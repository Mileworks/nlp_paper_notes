[100 Must-Read NLP Papers](https://github.com/mhagiwara/100-nlp-papers) 

[NLP progress](https://github.com/sebastianruder/NLP-progress)



:star: - ablation analysis



## Segmentation, Tagging, Parsing, SRL

* Michael Collins: [Head-Driven Statistical Models for Natural Language Parsing](http://www.cs.columbia.edu/~mcollins/papers/thesis.ps), PhD Dissertation, University of Pennsylvania, 1999.
* Michael Collins: [Discriminative Training Methods for Hidden Markov Models: Theory and Experiments with Perceptron Algorithms](http://www.cs.columbia.edu/~mcollins/papers/tagperc.pdf), EMNLP 2002. *(Received Best Paper Award)* 



* Simple and Accurate Dependency Parsing Using Bidirectional LSTM Feature Representations, Eliyahu Kiperwasser, Yoav Goldberg, TACL 2016 [arxiv](https://arxiv.org/abs/1603.04351) 
* Deep Semantic Role Labeling: What Works and What’s Next, He Luheng, Lee Kenton, Lewis Mike, [Zettlemoyer Luke](https://scholar.google.com/citations?user=UjpbO6IAAAAJ&hl=zh-CN&oi=sra), ACL 2017 [paper](https://aclanthology.info/papers/P17-1044/p17-1044) :star: 



## Machine Translation & Transliteration, Sequence-to-Sequence Models

+ Attention Is All You Need, Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin, 2017. [arxiv](https://arxiv.org/abs/1706.03762) 



## Automatic Text Summarization

- Get To The Point: Summarization with Pointer-Generator Networks, Abigail See, Peter J. Liu, Christopher D. Manning, ACL 2017 [arxiv](https://arxiv.org/abs/1704.04368v1) | [code](https://github.com/abisee/pointer-generator) | [pytorch code](https://github.com/atulkum/pointer_summarizer) 
- 


## Neural Models

- Matthew E. Peters, et al.: Deep contextualized word representations, 2018. [arxiv](https://arxiv.org/abs/1802.05365?context=cs) 
- Jacob Devlin, et al.: BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding, 2018. [arxiv](https://arxiv.org/abs/1810.04805?context=cs) :star: ​
- 