### Question

+ how to select proper parameters for transformer ?

  



### Case

+ transformer case [code](<https://github.com/tensorflow/tensor2tensor>) :star::star::star::star::star:
+ sentiment analysis [site](<https://mc.ai/deep-learning-in-production-sentiment-analysis-with-the-transformer-model/>) [code](<https://github.com/cortexlabs/cortex/blob/master/examples/pipelines/reviews/implementations/models/transformer.py>) 



### Paper

+ Augmenting Self-attention with Persistent Memory

+ Adaptive Attention Span for Transformers, Sainbayar Sukhbaatar, Edouard Grave, Piotr Bojanowski, Armand Joulin, ACL 2019 [arxiv](<https://arxiv.org/abs/1905.07799>) [code](<https://github.com/facebookresearch/adaptive-span>) 

+ sparse transformer

  Generating Long Sequences with Sparse Transformers, Rewon Child, Scott Gray, Alec Radford, Ilya Sutskever, [arxiv](<https://arxiv.org/abs/1904.10509>) [code](<https://github.com/openai/sparse_attention>) 

+ Training Tips for the Transformer Model, Martin Popel, Ond≈ôej Bojar, PBML [arxiv](<https://arxiv.org/abs/1804.00247>) 

  